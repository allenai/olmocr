# Enhanced Testing Infrastructure for OLMoCR

## üéØ Overview

This enhanced testing infrastructure provides comprehensive testing capabilities for OLMoCR, including property-based testing, performance regression detection, mock-based external dependency testing, and 80%+ code coverage validation.

## üèóÔ∏è Architecture

### Core Components

- **`base_test.py`** - Base test classes with automatic setup/cleanup and LogContext integration
- **`fixtures.py`** - Test data generation for forms, invoices, tables, and mock pipeline components
- **`mocks.py`** - Mock external dependencies (SGLang server, S3, file system) with realistic behavior
- **`property_testing.py`** - Property-based testing framework for edge case discovery
- **`performance_testing.py`** - Performance regression testing with baseline comparison
- **`integration_helpers.py`** - End-to-end integration testing utilities
- **`coverage_utils.py`** - Coverage tracking and module-level analysis tools

## üöÄ Quick Start

### Basic Test Class

```python
from tests.testing_framework import BaseOLMoCRTest, TestFixtures

class TestMyComponent(BaseOLMoCRTest):
    def test_document_processing(self):
        # Automatic test environment setup
        content = TestFixtures.create_sample_form_content()
        
        # Create test file with automatic cleanup
        test_file = self.create_test_file("input.txt", content)
        
        # Your test logic here
        result = process_document(test_file)
        
        # Enhanced assertions
        self.assert_file_exists(test_file)
        self.assertGreater(len(result), 0)
        
        # Cleanup happens automatically
```

### Property-Based Testing

```python
from tests.testing_framework import PropertyTestGenerator, run_property_tests

def test_document_processing_properties():
    generator = PropertyTestGenerator(seed=42)
    
    def test_property(content):
        result = process_document(content)
        return result is not None and len(str(result)) > 0
    
    results = run_property_tests(
        test_property,
        lambda: generator.generate_document_content("form"),
        iterations=100
    )
    
    assert results['success_rate'] > 0.95
```

### Performance Testing

```python
from tests.testing_framework import PerformanceTestRunner, benchmark_function

# Simple benchmarking
metrics = benchmark_function(my_function, iterations=100, warmup=10)
print(f"Average duration: {metrics.duration:.3f}s")

# Advanced performance testing
runner = PerformanceTestRunner()
metrics = runner.run_performance_test(
    "document_processing",
    process_document,
    iterations=50,
    warmup_iterations=5,
    test_content
)
```

### Mock-Based Testing

```python
from tests.testing_framework import create_mock_pipeline_components

def test_with_mocks():
    mocks = create_mock_pipeline_components()
    
    # Use mock SGLang server
    server = mocks['sglang_server']
    await server.start()
    
    # Use mock S3 client
    s3 = mocks['s3_client']
    s3.upload_file("local.txt", "bucket", "key")
    
    # Verify mock interactions
    assert server.request_count == 0
    assert s3.object_exists("bucket", "key")
```

## üß™ Test Categories

### Unit Tests
- **Base Classes**: `BaseOLMoCRTest`, `AsyncBaseOLMoCRTest`
- **Automatic Setup**: Temporary directories, mock objects, logging context
- **Enhanced Assertions**: File operations, content validation, performance checks

### Integration Tests
- **End-to-End**: Complete pipeline workflows with structured output
- **Environment Setup**: Isolated test environments with cleanup
- **Result Validation**: Output file verification and content checking

### Property-Based Tests
- **Edge Case Discovery**: Random data generation for comprehensive testing
- **Invariant Validation**: Consistency checks across different inputs
- **Document Types**: Forms, invoices, tables, contracts with realistic data

### Performance Tests
- **Regression Detection**: 10% degradation threshold with baseline comparison
- **Benchmarking**: Statistical analysis with warmup iterations
- **Trend Analysis**: Performance tracking over time

## üìä Coverage Analysis

### Module-Level Coverage
```python
from tests.testing_framework import generate_coverage_report

# Generate comprehensive coverage report
coverage_data = generate_coverage_report(
    source_root="olmocr",
    output_file="coverage_report.txt"
)

print(f"Overall coverage: {coverage_data['summary']['coverage_percentage']:.1f}%")
```

### Coverage Targets
- **Overall Target**: 80% code coverage across all modules
- **Critical Components**: 90% coverage for core pipeline and error handling
- **New Features**: 95% coverage for structured output functionality

## ‚ö° Running Tests

### Enhanced Test Suite Runner

```bash
# Run complete test suite with coverage and performance analysis
python tests/run_enhanced_test_suite.py

# Run with verbose output and save results
python tests/run_enhanced_test_suite.py --verbose --output test_results.json

# Run specific test categories
python tests/run_enhanced_test_suite.py --unit-only
python tests/run_enhanced_test_suite.py --performance-only
python tests/run_enhanced_test_suite.py --coverage-only
```

### Individual Test Modules

```bash
# Run comprehensive pipeline tests
python -m pytest tests/test_enhanced_pipeline_comprehensive.py -v

# Run structured output integration tests
python -m pytest tests/test_structured_output_integration.py -v

# Run with coverage
python -m pytest tests/ --cov=olmocr --cov-report=html
```

## üé≠ Mock Objects

### SGLang Server Mock
- **Configurable Delays**: Simulate realistic response times
- **Failure Injection**: Test error handling with configurable failure rates
- **Request Tracking**: Monitor and verify server interactions

### S3 Client Mock
- **In-Memory Storage**: Simulate S3 operations without external dependencies
- **Operation Tracking**: Verify upload/download operations
- **Error Simulation**: Test error conditions and retries

### File System Mock
- **Isolated Operations**: Test file operations without affecting real filesystem
- **Operation History**: Track all file system interactions
- **Error Injection**: Simulate file system errors and permissions issues

## üîß Configuration

### Testing Configuration
```python
from tests.testing_framework import get_testing_config, set_testing_config

# Get current configuration
config = get_testing_config()

# Update configuration
set_testing_config(
    default_timeout=60.0,
    performance_threshold=0.15,  # 15% degradation threshold
    coverage_target=85.0,        # Target 85% coverage
    property_test_iterations=200
)
```

### Environment Variables
```bash
# Enable debug logging for tests
export OLMOCR_TEST_DEBUG=1

# Set custom test timeout
export OLMOCR_TEST_TIMEOUT=60

# Enable performance profiling
export OLMOCR_TEST_PROFILE=1
```

## üéØ Best Practices

### Writing Tests
1. **Use Base Classes**: Inherit from `BaseOLMoCRTest` or `AsyncBaseOLMoCRTest`
2. **Isolate Tests**: Use temporary directories and mock objects
3. **Test Properties**: Use property-based testing for edge cases
4. **Performance Aware**: Include performance assertions for critical paths
5. **Integration Coverage**: Test end-to-end workflows

### Test Organization
1. **Descriptive Names**: Use clear, descriptive test method names
2. **Logical Grouping**: Group related tests in the same class
3. **Setup/Teardown**: Use setUp/tearDown for common test preparation
4. **Documentation**: Document complex test scenarios and expectations

### Mock Usage
1. **External Dependencies**: Mock all external services and APIs
2. **File Operations**: Use mock file systems for file operation tests
3. **Network Calls**: Mock all network communications
4. **Time-Dependent**: Mock time-dependent operations for consistency

## üìà Integration with OLMoCR Components

### Enhanced Error Handling Integration
- **LogContext Support**: Tests use structured logging and error context
- **Exception Testing**: Comprehensive testing of custom exception classes
- **Error Recovery**: Test error handling and recovery mechanisms

### Pipeline Refactoring Integration
- **Modular Testing**: Test individual pipeline components in isolation
- **Document Builder**: Test document building with and without structured output
- **Async Support**: Test asynchronous pipeline components

### Structured Output Integration
- **End-to-End Testing**: Test complete structured output workflows
- **Format Validation**: Test JSON output and schema compliance
- **Performance Impact**: Monitor performance impact of structured output

## üèÜ Benefits Achieved

### Quality Assurance
- **Comprehensive Coverage**: 80%+ code coverage across all modules
- **Regression Prevention**: Automated detection of performance and functional regressions
- **Edge Case Testing**: Property-based testing covers edge cases automatically
- **Integration Validation**: End-to-end testing ensures system integration

### Developer Productivity
- **Fast Feedback**: Quick test execution with parallel processing
- **Easy Debugging**: Rich logging and context information
- **Consistent Environment**: Standardized test setup and teardown
- **Performance Insights**: Continuous performance monitoring

### Maintainability
- **Modular Framework**: Reusable testing components
- **Clear Documentation**: Comprehensive testing guidelines
- **Automated Reporting**: Detailed test and coverage reports
- **CI/CD Integration**: Seamless integration with development workflows

---

## üéâ Enhanced Testing Infrastructure Success

The enhanced testing infrastructure provides:

- ‚úÖ **80%+ Code Coverage** across all OLMoCR modules
- ‚úÖ **Property-Based Testing** for comprehensive edge case coverage
- ‚úÖ **Performance Regression Detection** with automated baselines
- ‚úÖ **Mock-Based Testing** for reliable external dependency isolation
- ‚úÖ **Integration Testing** for end-to-end workflow validation
- ‚úÖ **Comprehensive Documentation** and usage guidelines

**Ready for production use in OLMoCR testing and continuous integration!** üöÄ
