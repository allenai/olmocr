#!/usr/bin/env python3
"""
Demonstration script for enhanced error handling system.

This script demonstrates the comprehensive error handling, structured logging,
and recovery mechanisms implemented for the OLMoCR pipeline.
"""

import asyncio
import json
import tempfile
import time
from typing import Dict, Any

# Import the enhanced error handling system
from olmocr.error_handling import (
    StructuredLogger, LogContext, create_logger,
    ErrorCategory, ErrorSeverity, OLMoCRError, NetworkError, ProcessingError,
    create_recovery_manager, create_error_aggregator, create_performance_monitor,
    correlation_context
)


async def demo_structured_logging():
    """Demonstrate structured logging capabilities."""
    print("üîç Demonstrating Structured Logging...")
    
    # Create a structured logger
    logger = create_logger("demo.structured_logging", structured=True)
    
    # Basic logging with context
    with logger.context(document_id="demo-doc-123", processing_stage="demo"):
        logger.info("Starting document processing")
        logger.debug("Loading document metadata")
        logger.warning("Document has unusual formatting")
    
    # Operation timing
    with logger.operation("document_analysis", document_id="demo-doc-123"):
        # Simulate some work
        await asyncio.sleep(0.1)
        logger.info("Analysis completed successfully")
    
    # Performance logging
    logger.performance(
        "Document processing completed",
        metrics={
            'pages_processed': 10,
            'processing_time_seconds': 5.2,
            'memory_usage_mb': 150.5
        }
    )
    
    print("   ‚úÖ Structured logging demonstrated")
    print()


async def demo_error_categorization():
    """Demonstrate error categorization and custom exceptions."""
    print("üè∑Ô∏è Demonstrating Error Categorization...")
    
    logger = create_logger("demo.error_categorization")
    
    # Create different types of errors
    errors = [
        NetworkError("Connection timeout to SGLang server"),
        ProcessingError("Failed to extract text from page 5"),
        OLMoCRError(
            "Invalid document format",
            ErrorCategory.VALIDATION,
            ErrorSeverity.HIGH,
            recoverable=False
        )
    ]
    
    for error in errors:
        logger.error(f"Error occurred: {error.message}")
        print(f"   üìã {error.__class__.__name__}: {error.category.value} ({error.severity.value})")
        print(f"      Recoverable: {error.recoverable}")
        if error.retry_after:
            print(f"      Retry after: {error.retry_after}s")
    
    print("   ‚úÖ Error categorization demonstrated")
    print()


async def demo_retry_strategies():
    """Demonstrate retry strategies and recovery mechanisms."""
    print("üîÑ Demonstrating Retry Strategies...")
    
    logger = create_logger("demo.retry_strategies")
    recovery_manager = create_recovery_manager(
        max_attempts=3,
        base_delay=0.1,
        logger=logger
    )
    
    # Simulate operation that succeeds after retries
    attempt_count = 0
    
    async def flaky_operation():
        nonlocal attempt_count
        attempt_count += 1
        print(f"   üîÑ Attempt {attempt_count}")
        
        if attempt_count < 3:
            raise NetworkError("Temporary connection failure")
        return "Operation successful!"
    
    try:
        result = await recovery_manager.execute_with_retry(
            flaky_operation,
            operation_name="demo_flaky_operation"
        )
        print(f"   ‚úÖ {result}")
    except Exception as e:
        print(f"   ‚ùå Operation failed: {e}")
    
    # Simulate non-recoverable error
    async def non_recoverable_operation():
        raise OLMoCRError(
            "Configuration error",
            ErrorCategory.CONFIGURATION,
            ErrorSeverity.CRITICAL,
            recoverable=False
        )
    
    try:
        await recovery_manager.execute_with_retry(
            non_recoverable_operation,
            operation_name="demo_non_recoverable"
        )
    except OLMoCRError as e:
        print(f"   ‚ö†Ô∏è Non-recoverable error (no retries): {e.message}")
    
    print("   ‚úÖ Retry strategies demonstrated")
    print()


async def demo_error_aggregation():
    """Demonstrate error aggregation and reporting."""
    print("üìä Demonstrating Error Aggregation...")
    
    logger = create_logger("demo.error_aggregation")
    aggregator = create_error_aggregator(logger)
    
    # Simulate various errors occurring
    errors_to_simulate = [
        NetworkError("Connection timeout"),
        NetworkError("Server unavailable"),
        ProcessingError("PDF parsing failed"),
        ProcessingError("Image extraction failed"),
        OLMoCRError("Memory limit exceeded", ErrorCategory.RESOURCE, ErrorSeverity.HIGH),
    ]
    
    for i, error in enumerate(errors_to_simulate):
        aggregator.record_error(error, retry_count=i % 3)
        await asyncio.sleep(0.01)  # Small delay to show time progression
    
    # Get summary
    summary = aggregator.get_summary()
    print(f"   üìà Total errors: {summary.total_errors}")
    print(f"   üìà Recoverable errors: {summary.recoverable_errors}")
    print(f"   üìà Non-recoverable errors: {summary.non_recoverable_errors}")
    
    print("   üìà Errors by category:")
    for category, count in summary.errors_by_category.items():
        print(f"      {category.value}: {count}")
    
    print("   üìà Errors by severity:")
    for severity, count in summary.errors_by_severity.items():
        print(f"      {severity.value}: {count}")
    
    # Generate comprehensive report
    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
        aggregator.export_report(f.name, include_diagnostics=True)
        print(f"   üíæ Detailed report exported to: {f.name}")
    
    print("   ‚úÖ Error aggregation demonstrated")
    print()


async def demo_performance_monitoring():
    """Demonstrate performance monitoring capabilities."""
    print("‚ö° Demonstrating Performance Monitoring...")
    
    logger = create_logger("demo.performance_monitoring")
    monitor = create_performance_monitor(logger)
    
    # Simulate various operations
    operations = [
        ("pdf_download", 0.5, True),
        ("page_rendering", 0.3, True),
        ("text_extraction", 0.2, True),
        ("model_inference", 1.2, True),
        ("pdf_download", 0.4, False),  # Failed operation
        ("page_rendering", 0.25, True),
    ]
    
    for op_name, duration, success in operations:
        if success:
            with monitor.time_operation(op_name):
                await asyncio.sleep(duration * 0.1)  # Scaled down for demo
        else:
            try:
                with monitor.time_operation(op_name):
                    await asyncio.sleep(duration * 0.1)
                    raise NetworkError("Simulated failure")
            except NetworkError:
                pass
    
    # Get performance summary
    summary = monitor.get_summary()
    print(f"   üìä Total operations: {summary['total_operations']}")
    print(f"   üìä Success rate: {summary['overall_success_rate']:.2%}")
    
    print("   üìä Operations breakdown:")
    for op_name, stats in summary['operations_by_type'].items():
        print(f"      {op_name}:")
        print(f"        Count: {stats['total_count']}")
        print(f"        Success rate: {stats['success_rate']:.2%}")
        print(f"        Avg duration: {stats['average_duration_seconds']:.3f}s")
    
    print("   ‚úÖ Performance monitoring demonstrated")
    print()


async def demo_correlation_tracking():
    """Demonstrate correlation ID tracking across operations."""
    print("üîó Demonstrating Correlation Tracking...")
    
    logger = create_logger("demo.correlation_tracking")
    
    # Use correlation context
    with correlation_context("demo-correlation-123") as correlation_id:
        print(f"   üÜî Correlation ID: {correlation_id}")
        
        # All operations within this context will share the correlation ID
        with logger.context(document_id="demo-doc", processing_stage="preprocessing"):
            logger.info("Starting document preprocessing")
            
            # Simulate nested operations
            with logger.operation("extract_metadata"):
                await asyncio.sleep(0.05)
                logger.info("Metadata extracted successfully")
            
            with logger.operation("validate_format"):
                await asyncio.sleep(0.03)
                logger.info("Format validation completed")
        
        logger.info("Document preprocessing completed")
    
    print("   ‚úÖ Correlation tracking demonstrated")
    print()


async def demo_enhanced_http_client():
    """Demonstrate enhanced HTTP client with error handling."""
    print("üåê Demonstrating Enhanced HTTP Client...")
    
    # Import the enhanced HTTP client
    from olmocr.pipeline.http_client import create_sglang_client, SGLangHTTPClient
    
    logger = create_logger("demo.http_client")
    
    # Create client with enhanced error handling
    try:
        client = await create_sglang_client(port=30024, logger=logger)
        print(f"   ‚úÖ HTTP client created for {client.base_url}")
        
        # The client now has:
        print("   üîß Enhanced features:")
        print("      - Structured logging with correlation IDs")
        print("      - Automatic retry with exponential backoff")
        print("      - Performance monitoring and metrics")
        print("      - Comprehensive error categorization")
        print("      - Graceful degradation on failures")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è Client creation demo (expected without server): {e}")
    
    print("   ‚úÖ Enhanced HTTP client demonstrated")
    print()


async def main():
    """Run all demonstrations."""
    print("=" * 70)
    print("üöÄ Enhanced Error Handling System Demonstration")
    print("=" * 70)
    print()
    
    print("This demonstration shows the comprehensive error handling")
    print("enhancements implemented for the OLMoCR pipeline:")
    print()
    
    # Run all demonstrations
    await demo_structured_logging()
    await demo_error_categorization()
    await demo_retry_strategies()
    await demo_error_aggregation()
    await demo_performance_monitoring()
    await demo_correlation_tracking()
    await demo_enhanced_http_client()
    
    print("=" * 70)
    print("‚úÖ ENHANCED ERROR HANDLING DEMONSTRATION COMPLETE!")
    print("=" * 70)
    print()
    print("Key improvements implemented:")
    print("  üîç Structured logging with correlation IDs and context")
    print("  üè∑Ô∏è Comprehensive error categorization and severity levels")
    print("  üîÑ Intelligent retry strategies with exponential backoff")
    print("  üìä Error aggregation and detailed reporting")
    print("  ‚ö° Performance monitoring and metrics collection")
    print("  üîó Correlation tracking across distributed operations")
    print("  üåê Enhanced HTTP client with robust error handling")
    print()
    print("Benefits achieved:")
    print("  ‚úÖ Better debugging and troubleshooting capabilities")
    print("  ‚úÖ Improved reliability with automatic error recovery")
    print("  ‚úÖ Comprehensive monitoring and observability")
    print("  ‚úÖ Graceful degradation under failure conditions")
    print("  ‚úÖ Detailed error reports for issue resolution")
    print()
    print("Ready for production use! üéâ")


if __name__ == "__main__":
    asyncio.run(main())
